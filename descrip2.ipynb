{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1066e2-b889-45cf-a88a-84282ef16d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football Video Action Recognition System\n",
      "==================================================\n",
      "Analyzing football video:\n",
      "Duration: 15.3 seconds\n",
      "FPS: 24.0\n",
      "Total frames: 367\n",
      "--------------------------------------------------\n",
      "At 0.4s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 0.8s: 1 player(s) detected Players standing or waiting for play to develop with moderate pace movement\n",
      "At 1.2s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 1.6s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "Progress: 13.1%\n",
      "At 2.0s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 2.4s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 2.8s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 3.2s: 2 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "Progress: 26.2%\n",
      "At 3.6s: 4 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 4.0s: 3 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 4.4s: 3 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 4.8s: 5 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "Progress: 39.2%\n",
      "At 5.2s: 2 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 5.6s: 3 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 6.0s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 6.4s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "Progress: 52.3%\n",
      "At 6.8s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "Players moving into position or walking with rapid movement detected\n",
      "At 7.6s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 8.0s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "Progress: 65.4%\n",
      "At 8.4s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 8.8s: 1 player(s) detected Players moving into position or walking with slow, controlled movement\n",
      "At 9.2s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "Players standing or waiting for play to develop with slow, controlled movement\n",
      "Progress: 78.5%\n",
      "At 10.0s: 1 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 10.4s: 2 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 10.8s: 3 player(s) detected Players standing or waiting for play to develop with moderate pace movement\n",
      "At 11.2s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "Progress: 91.6%\n",
      "At 11.6s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 12.0s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "\n",
      "Processed 367 frames\n",
      "Video analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.video import r3d_18\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "class FootballActionRecognizer:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained 3D ResNet model\n",
    "        self.model = r3d_18(pretrained=True)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Transform for preprocessing video frames\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], \n",
    "                               std=[0.22803, 0.22145, 0.216989])\n",
    "        ])\n",
    "        \n",
    "        # Buffer to store frames for temporal analysis\n",
    "        self.frame_buffer = deque(maxlen=16)  # 16 frames for 3D CNN\n",
    "        \n",
    "        # Football-specific action classes (simplified)\n",
    "        self.actions = [\n",
    "            \"running\", \"kicking\", \"passing\", \"dribbling\", \"tackling\",\n",
    "            \"jumping\", \"heading\", \"goalkeeping\", \"celebrating\", \"walking\"\n",
    "        ]\n",
    "        \n",
    "        # Object detection for players (using YOLO-like detection)\n",
    "        self.player_detector = cv2.HOGDescriptor()\n",
    "        self.player_detector.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "        \n",
    "    def detect_players(self, frame):\n",
    "        \"\"\"Detect players in the frame using HOG descriptor\"\"\"\n",
    "        try:\n",
    "            # Convert to RGB if needed\n",
    "            if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "                detection_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                detection_frame = frame\n",
    "                \n",
    "            players, weights = self.player_detector.detectMultiScale(\n",
    "                detection_frame, winStride=(8, 8), padding=(32, 32), scale=1.05\n",
    "            )\n",
    "            return players\n",
    "        except Exception as e:\n",
    "            print(f\"Player detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_motion(self, prev_frame, curr_frame):\n",
    "        \"\"\"Analyze motion between frames using frame difference\"\"\"\n",
    "        if prev_frame is None:\n",
    "            return \"stationary\"\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate frame difference\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray)\n",
    "        \n",
    "        # Apply threshold to get binary image\n",
    "        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Calculate motion as percentage of changed pixels\n",
    "        motion_pixels = cv2.countNonZero(thresh)\n",
    "        total_pixels = thresh.shape[0] * thresh.shape[1]\n",
    "        motion_percentage = (motion_pixels / total_pixels) * 100\n",
    "        \n",
    "        # Classify motion based on percentage of changed pixels\n",
    "        if motion_percentage > 15:\n",
    "            return \"fast_movement\"\n",
    "        elif motion_percentage > 8:\n",
    "            return \"moderate_movement\"  \n",
    "        elif motion_percentage > 3:\n",
    "            return \"slow_movement\"\n",
    "        else:\n",
    "            return \"stationary\"\n",
    "    \n",
    "    def classify_action(self, frame_sequence):\n",
    "        \"\"\"Classify action from frame sequence\"\"\"\n",
    "        if len(frame_sequence) < 8:\n",
    "            return \"analyzing\"\n",
    "        \n",
    "        # Simple heuristic-based classification for football actions\n",
    "        # In practice, you'd use a trained model on football-specific data\n",
    "        \n",
    "        # Analyze frame differences and patterns\n",
    "        motion_scores = []\n",
    "        for i in range(1, len(frame_sequence)):\n",
    "            diff = cv2.absdiff(frame_sequence[i-1], frame_sequence[i])\n",
    "            motion_score = np.mean(diff)\n",
    "            motion_scores.append(motion_score)\n",
    "        \n",
    "        avg_motion = np.mean(motion_scores)\n",
    "        motion_variance = np.var(motion_scores)\n",
    "        \n",
    "        # Classify based on motion patterns\n",
    "        if avg_motion > 30 and motion_variance > 100:\n",
    "            return \"kicking_or_tackling\"\n",
    "        elif avg_motion > 20:\n",
    "            return \"running_or_dribbling\"\n",
    "        elif avg_motion > 10:\n",
    "            return \"walking_or_positioning\"\n",
    "        else:\n",
    "            return \"stationary_or_waiting\"\n",
    "    \n",
    "    def generate_description(self, players, action, motion_type, frame_count):\n",
    "        \"\"\"Generate natural language description\"\"\"\n",
    "        timestamp = frame_count / 30.0  # Assuming 30 FPS\n",
    "        \n",
    "        descriptions = []\n",
    "        \n",
    "        # Player count description\n",
    "        if len(players) > 0:\n",
    "            descriptions.append(f\"At {timestamp:.1f}s: {len(players)} player(s) detected\")\n",
    "        \n",
    "        # Action description\n",
    "        action_descriptions = {\n",
    "            \"kicking_or_tackling\": \"Players engaged in intense action - likely kicking ball or tackling\",\n",
    "            \"running_or_dribbling\": \"Players running across the field, possibly dribbling\",\n",
    "            \"walking_or_positioning\": \"Players moving into position or walking\",\n",
    "            \"stationary_or_waiting\": \"Players standing or waiting for play to develop\",\n",
    "            \"analyzing\": \"Analyzing player movements...\"\n",
    "        }\n",
    "        \n",
    "        if action in action_descriptions:\n",
    "            descriptions.append(action_descriptions[action])\n",
    "        \n",
    "        # Motion description\n",
    "        motion_descriptions = {\n",
    "            \"fast_movement\": \"with rapid movement detected\",\n",
    "            \"moderate_movement\": \"with moderate pace movement\",\n",
    "            \"slow_movement\": \"with slow, controlled movement\",\n",
    "            \"stationary\": \"with minimal movement\"\n",
    "        }\n",
    "        \n",
    "        if motion_type in motion_descriptions:\n",
    "            descriptions.append(motion_descriptions[motion_type])\n",
    "        \n",
    "        return \" \".join(descriptions)\n",
    "\n",
    "def analyze_football_video(video_path):\n",
    "    \"\"\"Main function to analyze football video\"\"\"\n",
    "    recognizer = FootballActionRecognizer()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Analyzing football video:\")\n",
    "    print(f\"Duration: {duration:.1f} seconds\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    frame_count = 0\n",
    "    prev_frame = None\n",
    "    frame_sequence = deque(maxlen=8)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Resize frame for processing\n",
    "            processed_frame = cv2.resize(frame, (640, 360))\n",
    "            frame_sequence.append(processed_frame)\n",
    "            \n",
    "            # Process every 12 frames (every 0.5 seconds at 24fps)\n",
    "            if frame_count % 12 == 0:\n",
    "                try:\n",
    "                    # Detect players\n",
    "                    players = recognizer.detect_players(processed_frame)\n",
    "                    \n",
    "                    # Analyze motion\n",
    "                    motion_type = recognizer.analyze_motion(prev_frame, processed_frame)\n",
    "                    \n",
    "                    # Classify action\n",
    "                    action = recognizer.classify_action(list(frame_sequence))\n",
    "                    \n",
    "                    # Generate description\n",
    "                    description = recognizer.generate_description(\n",
    "                        players, action, motion_type, frame_count\n",
    "                    )\n",
    "                    \n",
    "                    print(description)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error at frame {frame_count}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            prev_frame = processed_frame.copy()\n",
    "            \n",
    "            # Show progress\n",
    "            if frame_count % 48 == 0:  # Every 2 seconds at 24fps\n",
    "                progress = (frame_count / total_frames) * 100\n",
    "                print(f\"Progress: {progress:.1f}%\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during video processing: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        print(f\"\\nProcessed {frame_count} frames\")\n",
    "        print(\"Video analysis complete!\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Hello\\Downloads\\2932301-uhd_4096_2160_24fps.mp4\"\n",
    "    \n",
    "    print(\"Football Video Action Recognition System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        analyze_football_video(video_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing video: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Make sure the video file exists at the specified path\")\n",
    "        print(\"2. Install required packages: pip install opencv-python torch torchvision\")\n",
    "        print(\"3. Ensure the video format is supported by OpenCV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bd826a-dc67-4cce-af62-c0f62206b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football Video Action Recognition System\n",
      "==================================================\n",
      "Analyzing football video:\n",
      "Duration: 15.3 seconds\n",
      "FPS: 24.0\n",
      "Total frames: 367\n",
      "Press 'q' to quit, 'space' to pause/resume\n",
      "--------------------------------------------------\n",
      "At 0.4s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 0.8s: 1 player(s) detected Players standing or waiting for play to develop with moderate pace movement\n",
      "At 1.2s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 1.6s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 2.0s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 2.4s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 2.8s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 3.2s: 2 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 3.6s: 4 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 4.0s: 3 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 4.4s: 3 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 4.8s: 5 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 5.2s: 2 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 5.6s: 3 player(s) detected Players running across the field, possibly dribbling with rapid movement detected\n",
      "At 6.0s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 6.4s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 6.8s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "Players moving into position or walking with rapid movement detected\n",
      "At 7.6s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 8.0s: 1 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 8.4s: 2 player(s) detected Players moving into position or walking with rapid movement detected\n",
      "At 8.8s: 1 player(s) detected Players moving into position or walking with slow, controlled movement\n",
      "At 9.2s: 3 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 10.0s: 1 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 10.4s: 2 player(s) detected Players moving into position or walking with moderate pace movement\n",
      "At 10.8s: 3 player(s) detected Players standing or waiting for play to develop with moderate pace movement\n",
      "At 11.2s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 11.6s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "At 12.0s: 2 player(s) detected Players standing or waiting for play to develop with slow, controlled movement\n",
      "\n",
      "Processed 367 frames\n",
      "Video analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.video import r3d_18\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "class FootballActionRecognizer:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained 3D ResNet model\n",
    "        self.model = r3d_18(pretrained=True)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Transform for preprocessing video frames\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], \n",
    "                               std=[0.22803, 0.22145, 0.216989])\n",
    "        ])\n",
    "        \n",
    "        # Buffer to store frames for temporal analysis\n",
    "        self.frame_buffer = deque(maxlen=16)  # 16 frames for 3D CNN\n",
    "        \n",
    "        # Football-specific action classes (simplified)\n",
    "        self.actions = [\n",
    "            \"running\", \"kicking\", \"passing\", \"dribbling\", \"tackling\",\n",
    "            \"jumping\", \"heading\", \"goalkeeping\", \"celebrating\", \"walking\"\n",
    "        ]\n",
    "        \n",
    "        # Object detection for players (using YOLO-like detection)\n",
    "        self.player_detector = cv2.HOGDescriptor()\n",
    "        self.player_detector.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "        \n",
    "    def detect_players(self, frame):\n",
    "        \"\"\"Detect players in the frame using HOG descriptor\"\"\"\n",
    "        try:\n",
    "            # Convert to RGB if needed\n",
    "            if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "                detection_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                detection_frame = frame\n",
    "                \n",
    "            players, weights = self.player_detector.detectMultiScale(\n",
    "                detection_frame, winStride=(8, 8), padding=(32, 32), scale=1.05\n",
    "            )\n",
    "            return players\n",
    "        except Exception as e:\n",
    "            print(f\"Player detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_motion(self, prev_frame, curr_frame):\n",
    "        \"\"\"Analyze motion between frames using frame difference\"\"\"\n",
    "        if prev_frame is None:\n",
    "            return \"stationary\"\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate frame difference\n",
    "        diff = cv2.absdiff(prev_gray, curr_gray)\n",
    "        \n",
    "        # Apply threshold to get binary image\n",
    "        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Calculate motion as percentage of changed pixels\n",
    "        motion_pixels = cv2.countNonZero(thresh)\n",
    "        total_pixels = thresh.shape[0] * thresh.shape[1]\n",
    "        motion_percentage = (motion_pixels / total_pixels) * 100\n",
    "        \n",
    "        # Classify motion based on percentage of changed pixels\n",
    "        if motion_percentage > 15:\n",
    "            return \"fast_movement\"\n",
    "        elif motion_percentage > 8:\n",
    "            return \"moderate_movement\"  \n",
    "        elif motion_percentage > 3:\n",
    "            return \"slow_movement\"\n",
    "        else:\n",
    "            return \"stationary\"\n",
    "    \n",
    "    def classify_action(self, frame_sequence):\n",
    "        \"\"\"Classify action from frame sequence\"\"\"\n",
    "        if len(frame_sequence) < 8:\n",
    "            return \"analyzing\"\n",
    "        \n",
    "        # Simple heuristic-based classification for football actions\n",
    "        # In practice, you'd use a trained model on football-specific data\n",
    "        \n",
    "        # Analyze frame differences and patterns\n",
    "        motion_scores = []\n",
    "        for i in range(1, len(frame_sequence)):\n",
    "            diff = cv2.absdiff(frame_sequence[i-1], frame_sequence[i])\n",
    "            motion_score = np.mean(diff)\n",
    "            motion_scores.append(motion_score)\n",
    "        \n",
    "        avg_motion = np.mean(motion_scores)\n",
    "        motion_variance = np.var(motion_scores)\n",
    "        \n",
    "        # Classify based on motion patterns\n",
    "        if avg_motion > 30 and motion_variance > 100:\n",
    "            return \"kicking_or_tackling\"\n",
    "        elif avg_motion > 20:\n",
    "            return \"running_or_dribbling\"\n",
    "        elif avg_motion > 10:\n",
    "            return \"walking_or_positioning\"\n",
    "        else:\n",
    "            return \"stationary_or_waiting\"\n",
    "    \n",
    "    def generate_description(self, players, action, motion_type, frame_count):\n",
    "        \"\"\"Generate natural language description\"\"\"\n",
    "        timestamp = frame_count / 30.0  # Assuming 30 FPS\n",
    "        \n",
    "        descriptions = []\n",
    "        \n",
    "        # Player count description\n",
    "        if len(players) > 0:\n",
    "            descriptions.append(f\"At {timestamp:.1f}s: {len(players)} player(s) detected\")\n",
    "        \n",
    "        # Action description\n",
    "        action_descriptions = {\n",
    "            \"kicking_or_tackling\": \"Players engaged in intense action - likely kicking ball or tackling\",\n",
    "            \"running_or_dribbling\": \"Players running across the field, possibly dribbling\",\n",
    "            \"walking_or_positioning\": \"Players moving into position or walking\",\n",
    "            \"stationary_or_waiting\": \"Players standing or waiting for play to develop\",\n",
    "            \"analyzing\": \"Analyzing player movements...\"\n",
    "        }\n",
    "        \n",
    "        if action in action_descriptions:\n",
    "            descriptions.append(action_descriptions[action])\n",
    "        \n",
    "        # Motion description\n",
    "        motion_descriptions = {\n",
    "            \"fast_movement\": \"with rapid movement detected\",\n",
    "            \"moderate_movement\": \"with moderate pace movement\",\n",
    "            \"slow_movement\": \"with slow, controlled movement\",\n",
    "            \"stationary\": \"with minimal movement\"\n",
    "        }\n",
    "        \n",
    "        if motion_type in motion_descriptions:\n",
    "            descriptions.append(motion_descriptions[motion_type])\n",
    "        \n",
    "        return \" \".join(descriptions)\n",
    "\n",
    "def analyze_football_video(video_path):\n",
    "    \"\"\"Main function to analyze football video with display\"\"\"\n",
    "    recognizer = FootballActionRecognizer()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Analyzing football video:\")\n",
    "    print(f\"Duration: {duration:.1f} seconds\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(\"Press 'q' to quit, 'space' to pause/resume\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    frame_count = 0\n",
    "    prev_frame = None\n",
    "    frame_sequence = deque(maxlen=8)\n",
    "    \n",
    "    # Variables to store current analysis results\n",
    "    current_players = []\n",
    "    current_action = \"analyzing\"\n",
    "    current_motion = \"stationary\"\n",
    "    current_description = \"Starting analysis...\"\n",
    "    \n",
    "    paused = False\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            if not paused:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "                \n",
    "                # Resize frame for processing\n",
    "                processed_frame = cv2.resize(frame, (640, 360))\n",
    "                frame_sequence.append(processed_frame)\n",
    "                \n",
    "                # Process every 12 frames (every 0.5 seconds at 24fps)\n",
    "                if frame_count % 12 == 0:\n",
    "                    try:\n",
    "                        # Detect players\n",
    "                        current_players = recognizer.detect_players(processed_frame)\n",
    "                        \n",
    "                        # Analyze motion\n",
    "                        current_motion = recognizer.analyze_motion(prev_frame, processed_frame)\n",
    "                        \n",
    "                        # Classify action\n",
    "                        current_action = recognizer.classify_action(list(frame_sequence))\n",
    "                        \n",
    "                        # Generate description\n",
    "                        current_description = recognizer.generate_description(\n",
    "                            current_players, current_action, current_motion, frame_count\n",
    "                        )\n",
    "                        \n",
    "                        print(current_description)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Processing error at frame {frame_count}: {e}\")\n",
    "                \n",
    "                prev_frame = processed_frame.copy()\n",
    "            \n",
    "            # Create display frame (resize original frame for display)\n",
    "            display_frame = cv2.resize(frame if not paused else display_frame, (1200, 675))\n",
    "            \n",
    "            # Draw player bounding boxes\n",
    "            for (x, y, w, h) in current_players:\n",
    "                # Scale coordinates to display frame size\n",
    "                scale_x = 1200 / 640\n",
    "                scale_y = 675 / 360\n",
    "                x_display = int(x * scale_x)\n",
    "                y_display = int(y * scale_y)\n",
    "                w_display = int(w * scale_x)\n",
    "                h_display = int(h * scale_y)\n",
    "                \n",
    "                cv2.rectangle(display_frame, (x_display, y_display), \n",
    "                            (x_display + w_display, y_display + h_display), (0, 255, 0), 2)\n",
    "                cv2.putText(display_frame, 'Player', (x_display, y_display - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add overlay with analysis information\n",
    "            overlay = display_frame.copy()\n",
    "            cv2.rectangle(overlay, (10, 10), (600, 150), (0, 0, 0), -1)\n",
    "            cv2.addWeighted(overlay, 0.7, display_frame, 0.3, 0, display_frame)\n",
    "            \n",
    "            # Add text information\n",
    "            timestamp = frame_count / fps\n",
    "            info_lines = [\n",
    "                f\"Time: {timestamp:.1f}s / {duration:.1f}s\",\n",
    "                f\"Frame: {frame_count}/{total_frames}\",\n",
    "                f\"Players detected: {len(current_players)}\",\n",
    "                f\"Action: {current_action.replace('_', ' ').title()}\",\n",
    "                f\"Motion: {current_motion.replace('_', ' ').title()}\",\n",
    "                \"Press SPACE to pause, Q to quit\"\n",
    "            ]\n",
    "            \n",
    "            y_offset = 25\n",
    "            for line in info_lines:\n",
    "                cv2.putText(display_frame, line, (20, y_offset),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                y_offset += 20\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow('Football Action Recognition', display_frame)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord(' '):  # Space bar to pause/resume\n",
    "                paused = not paused\n",
    "                if paused:\n",
    "                    print(\"Video paused. Press SPACE to resume.\")\n",
    "                else:\n",
    "                    print(\"Video resumed.\")\n",
    "            \n",
    "            # Control playback speed to match original FPS\n",
    "            if not paused:\n",
    "                time.sleep(1.0 / fps)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during video processing: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"\\nProcessed {frame_count} frames\")\n",
    "        print(\"Video analysis complete!\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Hello\\Downloads\\2932301-uhd_4096_2160_24fps.mp4\"\n",
    "    \n",
    "    print(\"Football Video Action Recognition System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        analyze_football_video(video_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing video: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Make sure the video file exists at the specified path\")\n",
    "        print(\"2. Install required packages: pip install opencv-python torch torchvision\")\n",
    "        print(\"3. Ensure the video format is supported by OpenCV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a3d7b-1fb2-42b7-8be7-c49b35e79cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
